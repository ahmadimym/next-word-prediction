{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "import numpy as np \n",
    "import regex as re"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def file_to_sentence_list(file_path): \n",
    "    with open(file_path, 'r') as file: \n",
    "        text = file.read() \n",
    "    sentences = [sentence.strip() for sentence in re.split( \n",
    "        r'(?<=[.!?])\\s+', text) if sentence.strip()] \n",
    "  \n",
    "    return sentences \n",
    "  \n",
    "file_path = 'data.txt'\n",
    "text_data = file_to_sentence_list(file_path) \n",
    "  \n",
    "# Tokenize the text data \n",
    "tokenizer = Tokenizer() \n",
    "tokenizer.fit_on_texts(text_data) \n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "  \n",
    "# Create input sequences \n",
    "input_sequences = [] \n",
    "for line in text_data: \n",
    "    token_list = tokenizer.texts_to_sequences([line])[0] \n",
    "    for i in range(1, len(token_list)): \n",
    "        n_gram_sequence = token_list[:i+1] \n",
    "        input_sequences.append(n_gram_sequence) \n",
    "  \n",
    "# Pad sequences and split into predictors and label \n",
    "max_sequence_len = max([len(seq) for seq in input_sequences]) \n",
    "input_sequences = np.array(pad_sequences( \n",
    "    input_sequences, maxlen=max_sequence_len, padding='pre')) \n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1] \n",
    "  \n",
    "# Convert target data to one-hot encoding \n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e9aefce348f3553"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the model \n",
    "model = Sequential() \n",
    "model.add(\n",
    "    Embedding(\n",
    "        total_words,\n",
    "        10,\n",
    "        input_length=max_sequence_len-1\n",
    "    )\n",
    ") \n",
    "model.add(LSTM(128)) \n",
    "model.add(\n",
    "    Dense(\n",
    "        total_words,\n",
    "        activation='softmax'\n",
    "    )\n",
    ") \n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ") "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e428307ad7b495e3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train the model \n",
    "model.fit(\n",
    "    X,\n",
    "    y,\n",
    "    epochs=500,\n",
    "    verbose=1\n",
    ")  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "718b89245907c24e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Generate next word predictions \n",
    "seed_text = \"I do beg your good \"\n",
    "next_words = 5\n",
    "  \n",
    "for _ in range(next_words): \n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0] \n",
    "    token_list = pad_sequences( \n",
    "        [token_list],\n",
    "        maxlen=max_sequence_len-1,\n",
    "        padding='pre'\n",
    "    ) \n",
    "    predicted_probs = model.predict(token_list) \n",
    "    predicted_word = tokenizer.index_word[np.argmax(predicted_probs)] \n",
    "    seed_text += \" \" + predicted_word \n",
    "  \n",
    "print(\"Next predicted words:\", seed_text) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb69bac14f11faf8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
